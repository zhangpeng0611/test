#if 1

/*

//智能指针：
智能指针是一个类，私有成员变量为一个指针，其析构函数销毁指针，达到智能释放指针的效果，
本质就是利用栈上的对象出作用域自动调用析构函数，所以智能指针只能定义在栈上而不能定义在堆上。

auto_ptr:只有最后一个智能指针管理对象，前面的智能指针全部被置为了null;
scope_ptr:其拷贝构造函数和赋值构造函数都已经被私有化，所以只能允许单个指针管理对象
unique_ptr:虽然其拷贝构造函数和复制构造也被delete了，但是存在右值引用的拷贝和复制。
可以通过传入std::move();来进行

shared_ptr:可以允许多个指针管理资源对象，并且有引用计数，当引用计数为0时才能释放资源。
weak_ptr:只是资源的观察者，不能引用计数，也不能使用资源。
如果两个shared_ptr互相交叉引用的话，就会造成资源无法释放的问题，此时应该通过弱智能指针来解决
通过定义弱智能指针来应用对象，这样引用计数不会增加，不过当要访问资源的时候，需要将弱智能指针
提升为强智能指针，如果提升成功说明强智能指针引用计数不为0.失败则说明强智能指针引用计数为0；

std::enable_shared_from_this:
用于方便的在类对象中获取自身的std::shared_ptr，主要用于解决在类的成员函数中需要将当前对象作为
std::shared_ptr传递给其他函数。一个类要使用std::enable_shared_from_this必须要使用公有继承



多线程访问共享对象的安全问题时：需要去探测共享对象是否还存活，尝试将弱智能指针提升为强智能指针，
提升成功可以访问，提升失败则不能访问。

基类应该提供虚函数方法让派生类去重写基类的函数方法，并且基类的析构函数也需要为虚函数。
override关键字的作用：
用来显示的指定派生类重写基类的虚函数，并且编译器会检查基类对应的函数是否为虚函数

epoll_creat1(epoll_cloexec)：若这样设置的话，新创建的文件描述符会设置close-on-exec标志，这样在进程
调用exec函数时会关闭该文件描述符。

std::move移动语义：将一个对象的资源所有权直接转移而不是复制，把一个对象的资源窃取进
另一个对象，原对象进入可析构但通常为空的状态。

函数绑定器：将一个函数对象绑定某些参数使其变成一个新的函数对象
可以将一个函数与一系列参数绑定，生成一个新的可调用对象
语法：std::bind(function,arg1,arg2....)
参数中可以填入函数占位符：std::placeholder::_1,表示将函数参数帮到为占位符

线程函数:
detach函数：将线程与调用它的线程分离。
join函数：用于阻塞当前线程，它会等待指定的线程完成其任务，然后继续执行后续代码，起到线程同步的作用


RAll机制：将资源的管理与对象的生命周期绑定，在对象的构造函数中完成资源的申请，在对象的析构函数中完成
资源的释放，由于c++保证对象的析构函数会在对象生命周期结束时自动释放，无论是正常退出还是异常退出都可以
确保资源的释放始终被执行。
典型应用：智能指针管理内存，std::unique_ptr,std::shared_ptr。
线程同步，std::lock_guard,std::unique_lock。


//大小根堆定义方式
priority_queue<type,container,function>q;
type：数据类型；
container：实现优先队列的底层容器；
function：元素之间的比较方式，为less的时候表示大根堆

对于container，要求必须是数组形式实现的容器，例如vector、deque，而不能使list。
在STL中，默认情况下（不加后面两个参数）是以vector为容器，以 operator< 为比较方式，
所以在只使用第一个参数时，优先队列默认是一个最大堆，每次输出的堆顶元素是此时堆中的最大元素。


面经：
值传参和引用传参的区别：
值传参会将实际值复制一份传给函数作为形参，对形参的改变不会影响实参；
引用传参是将实际值的地址传给函数，形参的操作会影响实参。
值传参会产生数据复制，引用传参只会传地址。

typedef和using的区别:
1.typedef是从c继承过来的关键字，using是c++11标准的关键字
2.语法上： typedef 原类型 别名,  using 别名=原类型
3.typedef不支持直接定义模板别名，using可以直接定义模板的别名。
如下：
template <typename T>
typedef Container<T> AnyContainer; // 编译错误（T 未实例化）
template <typename T>
using AnyContainer = Container<T>; // 正确：为模板 Container 定义别名 AnyContainer


操作系统是如何管理进程和线程的：
1.操作系统都是通过控制块来管理进程和线程的，进程是PCB,线程是TCB，并且控制块中都包含了线程/进程状态
和CPU上下文等相关信息，将相同状态的控制块用链表连接起来进行管理。
2.操作系统都以提高CPU利用率为目的对进程和线程采取了各种调度算法

堆和栈的区别以及操作系统是怎么管理堆栈的：
1.栈是由操作系统自动分配和释放的，堆是由程序员手动申请和释放
2.栈主要用来存储函数的返回值，函数局部变量，参数。堆主要存储动态分配的对象和数组
3.栈的大小固定，可能会出现栈逸出的问题。堆的空间大小比较灵活

操作系统对于栈的管理核心是通过栈帧实现对函数调用的内存隔离
操作系统对于堆的管理核心是通过查找空闲链表，该空闲链表存储的是空闲的内存页。

操作系统是怎么管理内存的：
1.虚拟内存——》页表——》进行展开
2.分配内存-》new,malloc-》malloc底层实现展开
3.内存回收-》后台内存回收，直接内存回收-》OOM-》根据页面置换算法选择淘汰的内存页
 
DNS解析的核心流程：
DNS 解析的本质是：客户端通过 socket 向 DNS 服务器发送 “域名→IP” 的查询请求，再通过 socket 
接收服务器返回的解析结果。
创建一个udp的socket(DNS优先使用udp)->获取DNS服务器地址->创建DNS查询报文->通过socket的sendto函数
发送查询报文->通过recvfrom接收DNS服务器发送回来的响应报文->解析响应报文并关闭socket

为什么DNS解析时优先使用UDP的socket：
DNS 作为互联网的 “地址簿”，其核心诉求是快速完成域名到 IP 地址的映射，
而 UDP 协议的特性完美适配这一需求。udp不需要建立连接，直接发送数据报即可，对于单次的DNS查询，可以
缩短查询时间

DNS劫持：攻击者将DNS解析的传回给客户端的响应包中的ip地址篡改成攻击者所能掌控的非法的ip地址。
主要有：1.客户端劫持 :篡改客户端本地的域名，使其所对应的ip地址为攻击者掌控的非法地址
        2.DNS服务器劫持：篡改DNS服务器的解析记录，将返回给客户端的响应报文中的ip地址指向攻击者所掌控
        的非法ip地址
        3.中间人攻击：在 DNS 查询过程中，攻击者在用户与 DNS 服务器之间充当中间人，篡改 DNS 响应包
        将域名解析结果替换为攻击者控制的 IP 地址。

怎么防止DNS劫持：
1.采用加密的https访问网站，其内部的证书链可以验证网站的真实性

区分数字证书和数字签名：
1.数字证书是由CA产生的，服务端将自己的公钥交给CA,CA用自己的私钥对服务器的公钥进行加密形成数字证书，
然后发给客户端，客户端本地一般拥有CA的公钥，通过CA公钥解密出服务器的公钥，这属于混合加密中的非对称
加密过程。
2.数字签名：假设A给B发送数据，A首先用哈希函数给要发送的数据计算出一个哈希值，然后A用自己的私钥
给这个哈希值进行加密，加密的结果就是数字签名，然后A将数字签名和数据发送给B,B通过从数字证书中拿到
A的公钥，然后用公钥进行解密获取到哈希值，并且B对数据进行哈希函数计算，两个哈希值进行比较

宏定义和inline函数:
https://www.cnblogs.com/yinbiao/p/11606554.html
 宏：是源码级别的文本替换，不会进行类型检查，宏的展开，替换发生在预处理阶段，不涉及函数调用，参数传递
 没有任何运行效率的损失，对于一些频繁调用的小段代码，用宏定义的方式比inline效果更好

 inline的作用以及是怎么提高函数运行效率的：
 inline的作用是将将函数调用替换为展开函数体代码，而不需要进行传统的函数调用。
 提高运行效率：因为普通函数调用时，程序需要执行一系列操作：保存当前上下文（如寄存器状态）
 跳转到函数地址、执行函数体、返回原地址并恢复上下文。系统需要在栈上为函数参数、返回地址、
 局部变量等分配空间（栈帧），函数执行结束后再释放这些空间。使用inline是直接在调用处插入函数体，
 可以减少上述开销。

 什么样的函数不适合定义为Inline:
 1.函数体过大的函数，比如包含了循环和递归的函数，编译器会忽略inline声明，按照普通函数进行处理
 2.虚函数通常不能被定义为inline函数，因为编译器在编译阶段无法确定调用的函数版本

动态断言(assert)和静态断言(static_assert)：
assert其实是个宏，但是却是在运行阶段起作用，所有叫做动态断言，判断结果是否为true，结果为false
abort停止。
static_assert是关键字，只在编译的时候起作用，在运行的时候看不见，所以叫做静态断言。由于是在
编译阶段起作用，所以看不到运行阶段的变量，指针，内存数据等，不能把运行阶段的数据写在静态断言里。


c++和c强制类型转换：
c语言强制类型转换：(目标类型)表达式，该类型转换为万能类型转换,不会进行类型检查，类型转换失败编译器
也不会报错。
c++强制类型转化：
static_cast<目标类型>(表达式)：
编译时转换：转换动作在编译期完成，不产生运行时开销。
基于类型关联性：仅允许在有明确转换规则的相关类型之间转换（如数值类型之间、基类与派生类之间）。
不进行运行时类型检查：编译器仅根据类型声明判断转换合法性，不会验证转换后的对象是否真
的属于目标类型（这一点与dynamic_cast不同）。
所以就是从派生类向基类转换没有问题，因为派生类完整的包含了基类部分，向上转换没有问题。但是反过来由基类
向派生类转换会有问题，因为不进行检查判断转换是否成功

dynamic_cast<目标类型>(表达式)：
主要用于动态多态类型转换，即用于基类和派生类之间的转换，会在运行时检查转换的有效性，确保转换结果的安全。
对于指针转换是失败会返回nullptr，对于引用转换失败会std::bad_cast异常
注意：dynamic_cast是通过运行时检查RTTI(运行时类型信息)进行判断的，运行时类型信息的存储是与虚函数表进行绑定的
只有包含虚函数的类才会生成虚函数表，RTTI 信息（如类的类型标识）通常存储在虚函数表的开头。
若类没有虚函数（如 B 中去掉 virtual void foo()），dynamic_cast 无法获取 RTTI，编译时会报错。
如果通过虚函数表查到实际类型为父类而并不是子类，则会判断转换失败，返回空指针或者报错

const_cast<目标类型>(表达式)：用于移除 const 或 volatile 修饰


const/volatile/mutable:
const虽然通常都说是常量修饰，但其实和宏定义是有区别的，因为const定义的常量在预处理阶段并不存在，
直到运行阶段才出现，所以其实const修饰的应该叫做只读变量比较合适。
由于const修饰的任然还是变量，是变量就可以通过指针修改其内存值，如以下这段代码：
const volatile int p=1024;
auto ptr=(int*)(&p); 
*ptr=2048
这段代码输出p的值为2048,这是由于了volatile关键字的作用（禁止编译器优化），该关键字的意思是不稳定的，
易变的，表明变量很容易被修改，所以需要每次都去到变量的内存地址去取值，刚刚修改了内存地址的值，
所以输出2048,而如果没有这个关键字，则输出1024，这是因为编译器看到const关键字在编译阶段会把没有用
到的2048给优化掉，所以最终输出的值还是1024
mutable只能修饰类的成员变量，表示即使在const函数对象里也可以修改

const可以修饰全局函数吗?
const一般用来限定某个对象或者变量是只读的，而函数本身就是一个不可修改的状态。
所以const不能用来修饰全局函数，只能修饰全局函数的参数或者返回值。
修饰变量：修饰的变量表示常量，初始化后不可被修改
指针常量：int *const p; 常量指针：const int* p;
修饰函数：类的成员函数用const修饰表示该函数不会修改类的任何变量
const修饰函数放在函数前和函数后的区别：
const放在函数前表示修饰函数的返回值为不可修改，为只读。const放在函数参数列表后表示该函数不会修改
类的任何非mutable变量，并且也只能调用其他的const函数

空类的大小为1个字节，C++ 标准规定，任何独立的对象都必须有唯一的内存地址
（即两个不同的对象不能共享同一块内存）。若空类大小为 0，当创建多个空类对象的时候可能会出现内存地址重合
违反每个对象内存地址唯一这一规则。
继承空基类的子类大小：
如果子类中没有任何数据成员的话，该子类大小一般也为1个字节，如果有数据成员或者虚函数的话，
需要加上其的大小。

含有虚函数的类的大小：
含有虚函数的类的至少包含一个指针，因为一个类含有虚函数的话就隐式的含有了一个指向虚函数表的虚表指针。

c++重载的底层实现：
C++编译器在编译阶段会对重载函数进行名字修饰（也称为名字改编），即根据函数的原始名称、
参数类型、参数数量等信息，生成一个唯一的内部标识符（修饰名），从而让 linker（链接器）
能够区分不同的重载函数。


虚函数和纯虚函数的区别：
虚函数用virtual修饰即可，而纯虚函数需要virtual...=0;虚函数在基类中可以有具体实现，为派生类提供一个
默认的实现，派生类也可以通过重写基类的虚函数来实现多态。纯虚函数在基类中没有具体实现，派生类必须
重写基类中的纯虚函数，否则派生类不能进行实例化对象。含有纯虚函数的类是抽象类，不能实例化对象，而
含有虚函数的类可以进行实例化对象。

bss段存的是未初始化的全局变量和静态变量，初始化为0的全局变量和静态变量。

const全局变量存在哪：
如果const修饰的全局变量或静态变量进行了初始化，就存在data段，如果没有初始化或者初始化为0就存在bss段
const修饰的局部变量存在栈区。


有什么办法修改const修饰的变量：
const修饰的变量一般是没办法修改的，不过可以通过const_cast来去除变量的const属性
如果const修饰的变量是通过指针指向的，而指针本身不是const，可以通过指针来修改所指向const变量的值。


构造函数和析构函数能否为虚函数：
构造函数的核心作用是初始化对象的成员变量，初始化虚表指针vptr,注意虚函数表是在编译阶段生成的。
如果构造函数为虚函数的话，那如果要调用构造函数则需要通过vptr查找虚函数表中的函数地址，但是又因为
构造函数为虚函数，此时vptr并未被初始化，所以会互相矛盾

析构函数可以为虚函数，因为如果基类析构函数不是虚函数的话，当基类指针删除派生类对象时只会调用基类的析构
函数，而不会调用派生类的析构函数，可能导致资源释放不充分。


new和malloc之间的区别：https://www.cnblogs.com/QG-whz/p/5140930.html
1.new是c++的关键字，malloc是c语言的库函数
2.new是从自由存储区上分配内存，malloc是从堆上分配内存。自由存储区是基于new的一个概念，凡是通过new
进行内存申请的，该内存即为自由存储区，自由存储区可以是堆，还可以是静态存储区，主要是看new在哪区分配内存。
可以通过operator new来自定义从哪来分配内存
3.new返回来的内存是具有对象类型的，而malloc返回的内存是void*类型
4.new分配内存失败后会返回bad_alloc，不会返回Null,而malloc分配失败会返回null
5.new分配内存时不需要指定大小，会根据数据类型自动分配，而malloc需要指定分配的内存大小。
6.new时调用构造函数构造对象，然后初始化，delete时先析构对象，再释放内存



free和delete的区别：
free是用来释放malloc申请的空间，delete是用来释放new申请出来的空间。
free只会释放内存空间，但是并不会调用对象的析构函数，而delete在释放内存空间的时候还会调用
对象的析构函数，对于释放数组内存空间可以使用delete[]，会调用数组每个元素的析构函数
delete需要接收new出来的特定类型的指针，而free接收void*类型的指针。


const T&可以接收右值吗：
const T&可以接收右值，因为const引用可以延长临时对象的生命周期，将右值绑定到const T&后，在引用的作用
域内，临时对象会一直存在。

快速排序什么时候退化成O(n*n):
数组序列已经有序或者数组元素全部相等，因为这个时候如果选择第一个元素作为基元素，则右区间会包含剩下
所有的元素，接着对右区间划分时也是一样的，会导致递归深度为n，从而导致时间复杂度为n平方。

内存对齐：
内存对齐是一种优化计算机内存访问的技术，它确保数据结构的起始地址能够按照一定的大小
（通常是2、4、8等）的倍数对齐。这样做可以提高内存访问的效率，因为对齐的地址允许CPU一次性读取或写入
更多的数据，而不需要多次访问内存。
举例：
假设CPU按4字节块访问内存，读取一个int类型数据（4 字节）：
若int起始地址是4的倍数（如 0x0004），CPU一次就能读取完整数据；
若起始地址是 0x0005（未对齐），CPU 需要先读 0x0004-0x0007，再读 0x0008-0x000B，
然后提取其中的 4 字节数据，效率降低。对于结构体，需要保持其成员对齐和整体对齐，其中整体对齐需要保持
结构体的总体大小需要为最大成员的对齐系数的倍数


空指针和野指针的区别：
空指针是明确初始化为nullptr的指针，它不指向任何有效的内存地址，而野指针是未被初始化或者被错误初始化，指向
了一个不确定的内存地址。
野指针产生：1.指针未被初始化 2.指针越界访问

拷贝构造函数和operator=()：
拷贝构造函数是一种特殊的构造函数，使用一个已经存在的对象来初始化另一个新对象，其函数原型为
classname(const classname& other)。在另一个新对象创建的时候调用，避免调用自身形成死循环
因为如果是值传参的话，需要给传入的对象创建一个副本，创建副本的这个过程又会调用拷贝构造函数，所以会形成死循环
operator=()是对赋值运算符进行重载，用于将一个已存在的对象赋值给另一个存在的对象，
classname& operator=(const classname& other)返回值为当前对象的引用。

memcpy和memmove的区别：
其函数参数都为 void* dst, const void* src,int n,在处理重叠内存区域的方式上，memcpy未定义对于重叠内存
区域的处理行为，memmove能够正确处理源内存块和目标内存块重叠的情况，会将源内存块复制到临时位置，再从
临时位置复制到目标位置。如果在源内存块和目标内存块不重叠时，使用memcpy效率会更高一点。

内存屏障：
1.指令重排序问题：为了提高执行效率，cpu会对指令的执行顺序进行优化重排，但是这在多线程中会导致不同
线程间数据不一致的问题。
2.缓存一致性的问题：线程操作的变量通常存于缓存中，而非直接写入主存。若多个 CPU 核心的缓存
未及时同步，会导致 “一个线程修改了变量，另一个线程看不到最新值” 的问题。
内存屏障就是解决这两个问题的：
1.LoadLoad---读读屏障
2.StoreStore---写写屏障
3.LoadStore---读写屏障
4.StoreLoad---写读屏障
以上屏障作用都是先保证执行完屏障的指令之后才执行屏障后的指令


互斥锁和自旋锁：
互斥锁是当一个线程去获取资源，如果没有获取到资源，就会阻塞住该线程，然后cpu会切换到其他线程进行执行，
而自旋锁在没有获得资源时会一种循环等待，cpu不会切换，直到获取到资源。


局部静态变量和全局静态变量的生存周期：
全局静态变量在main函数开始之前就完成初始化了，一直到main函数运行结束，程序退出时才销毁。
静态局部变量在运行到所处的那段代码的时候才初始化(延迟初始化)，销毁时机和全局静态变量一样。
静态函数：被static修饰的函数只能在定义它的文件内调用，不能被其他文件调用。

static修饰成员变量和成员函数的作用：
1.static修饰的成员变量属于整个类，所有对象共享这一份静态变量，该变量在内存中只存在一份。
在类内声明，在类外定义，定义的时候不加static关键字，可以通过类名::变量名进行访问
2.static修饰的成员函数属于整个类，不依赖具体对象，所以只能访问静态成员变量，不能访问其他的非静态
成员变量，因为非静态成员变量的访问依赖this指针。可以通过类名::函数名进行访问


引用与指针的区别：
引用是给已存在的对象取一个别名，它和引用对象共享同一块内存空间，定义时必须初始化，引用一旦被初始化之后就不能引用其他
变量了。
指针是一个变量，其值是另一个变量的内存地址，可指向不同的变量。
指针存储的是地址，占用额外的内存。引用在语法层面不占用额外的内存。
指针可以为nullptr,引用不可以为null。

访问对象成员时.和->的区别：
如果变量是对象或者引用的话，使用.来访问成员变量
如果变量是指向对象的指针的话，用->来访问成员变量，->的本质其实是(*指针).来访问成员变量


堆栈逸出一般是什么原因导致的：
栈逸出：无限递归，函数调用层级过深，局部变量过大，指针越界访问。
堆逸出：内存分配未释放，数组越界，内存碎片。

什么函数不能声明为虚函数：
虚函数属于类成员函数的一种特性，用于实现多态。
非成员函数不能声明为虚函数，因为它不属于任何类。

栈和队列的区别：
栈是一端开口，只允许先进后出，而队列是两端开口，先进先出，栈都是从栈顶入栈元素和出栈元素，而队列
从队头移除元素，从队尾添加元素。


extern关键字的作用：
extern用来声明外部变量或者是外部函数，主要用来实现跨文件的变量/函数共享
比如：在A文件中定义了一个全局变量int global_var=10;然后在B文件中可以通过extern int global_var来
进行声明外部变量，不需要进行初始化，这样链接器会自动找到A文件中该变量的定义。通过extern进行声明
时是不会分配内存的，如果不使用extern进行声明则会分配内存。如果使用extern声明时进行了初始化的话，此时
extern就会失效，可能会导致重复定义。
注意函数的声明本身就是extern的。

explicit关键字的作用：
explicit修饰单参数的的构造函数或者是只有第一个参数无默认值，其他参数有默认值的构造函数，作用是
禁止隐式类型转换，只能显式的调用构造函数

内存分区（计算机系统内存的宏观划分）：
栈区：由编译器自动分配和释放，存放的是函数的参数值和局部变量.栈区内存比较小
堆区：用于动态分配内存，由程序员手动开辟和释放，堆区内存比较大。
全局区/静态区：用于存放全局变量和静态变量
常量区：字符串常量，const常量等
代码区：二进制机器指令

用户空间分布：
从下往上：代码区-》数据区-》BSS区-》堆区-》文件映射区-》栈区-》内核空间

gcc四部曲：https://www.cnblogs.com/mickole/articles/3659112.html-c
预处理(-E)：处理源文件中的预处理指令，#include和#define所包含的
编译(-S)：对预处理后的文件进行词法分析,检查程序是否有语法错误，并生成汇编代码
汇编(-c)：将汇编代码转换为机器语言代码，生产目标文件
链接（-o）:将多个目标文件和用到的库文件进行链接，生成可执行文件
静态链接：
在链接阶段，将程序运行所依赖的代码全部复制到最终的可执行文件上
动态链接：
在链接阶段，仅在可执行文件中记录依赖的库名称和入口地址，而库代码本身不复制到可执行文件中。
程序运行时，查找并加载所需要的动态库到内存，将可执行文件中的库函数的引用与实际内存中的库文件
的地址绑定


三种基本的数据类型：
数值型，字符型，布尔型。

const和#define的区别：
const是定义为只读的关键字，而#define是预处理命令，const定义的变量操作时会检查数据类型是否符合，而
#define只进行简单的文本替换,const定义的变量的范围会不同,可以作为类的成员，#define的作用域是从定义开始
到文件结束，所以不能作为类的成员变量


数组如果频繁在头部进行插入应该怎么优化：
1.才有双端队列deque，双端队列头尾插入的时间复杂度为O(1),底层是分段的连续内存，支持随机访问
2.对数组中的数据采用逆向存储，这样在头部插入数据就变成了向尾部插入数据了


什么是中断：
中断是指当计算机在执行一个任务时，突然遇到了其他紧急的任务，从而暂停当前正在执行的任务去执行紧急的任务，
处理完成之后再返回原任务继续执行的过程。

共享内存如何使用：
shmget获取或者创建一块共享内存
shmat将共享内存映射到进程地址空间
进行数据读写操作，实现进程间的数据共享
使用shmdt将共享内存从地址空间中分离出来
使用shmctl删除共享内存

什么是同步，什么是互斥：
同步是指多个进程相互协调进行工作，使进程按照一定的顺序进行工作。
互斥是指同一时刻只有一个进程获得资源进行运行，而其他的进程需要等待资源的释放。


怎么实现进程间同步：
信号量：PV操作进行，初始化为0为同步信号量
互斥锁
条件变量：通常搭配互斥锁进行使用，当进程满足一定条件时才继续执行，不满足时则继续等待。
信号：信号是一种软件中断，一个进程向另一个进程发送信号，另一个进程收到信号后执行相应的
处理函数

TCP的缺点：
1.tcp建立连接的延迟
2.tcp会发生队头阻塞
3.网络变化时需要重新建立tcp连接

UDP为什么可以实现一对多，多对一，多对多的通信：
因为UDP是无状态，无连接的，它可以直接向目标地址发送数据报，接收方只要监听特定的端口就能接收
来自任何发送方的数据。

udp可不可以实现数据的可靠传输：
通过QUIC协议实现可靠传输：
协议中有packet header和QUIC frame header：packet header采用单调递增的方式，这样可以不用
像tcp那样进行有序确认，可以支持无序确认。QUIC frame header通过采用streamid+offset的方式来判断
重传的数据包与丢失的数据包数据是否一致。
QUIC由于每个stream都在一个http连接中，所以一个stream中的数据丢失不会影响其他stream，只会阻塞
这一个stream,stream到达应用层之后就会直接读取数据。
QUIC内部包含了tls，并且QUIC使用的是tls1.3，所以只需要1RRT就能建立连接。
QUIC通过连接id来定位两端并复用连接的。

线程池的概念及线程池的设计：
线程池创建的时候会有几个核心线程，当任务到达时如果核心线程空闲则直接分配线程进行执行，如果核心线程
繁忙则会创建新线程进行执行，这些新线程为非核心线程。当线程池中的线程达到最大数量时，并且都处于繁忙
状态，再有任务到来，任务会存放在任务队列，等待空闲线程去取任务执行。当任务队列也满了的时候，则会采用
拒绝策略：直接抛出异常，不执行任务；直接丢弃任务；淘汰任务队列里最老的任务，然后接收新任务。

核心线程的设计和最大线程数：
1.如果执行的是密集型的任务，则核心线程数=CPU核心数。如果执行的是IO密集型的任务的话,核心线程数=2*CPU核心数
2.空闲线程的回收策略：当任务量减小时，超出核心线程数的空闲线程应该及时销毁，释放资源。为每个空闲
线程设置超时时间，超出超时时间还没有获取到任务则自动退出。
3.任务队列是线程池的“缓冲区”，用于平衡生产者（提交任务）和消费者（线程）的速度，
需解决线程安全、容量控制和任务调度问题：队列必须支持多线程并发读写，需通过互斥锁（mutex）
和条件变量（condition_variable） 实现同步：生产者提交任务时，若队列未满则插入，否则阻塞或
采取其他策略。消费者线程从队列取任务时，若队列为空则阻塞，直到有新任务到来

怎么解决慢sql的：
优化查询语句，避免使用select *,优化where语句
索引优化：前缀索引优化，覆盖索引优化，主键自增优化，避免索引失效

慢sql会有什么问题：
查询时间长，并发量下降，由于查询时间长，其他事务可能对数据有更新，导致数据不一致

怎么分析查询语句，关心哪些参数：
可以通过explain分析语句，也可以通过慢查询日志分析语句。
具体应该关系 实际使用的索引，索引的长度，额外信息

http和rpc的区别：
服务发现：http通过本地DNS服务去获取Ip和port，而rpc通常通过中间件保存了服务的信息，想访问服务需要先去
中间件进行查询。
底层连接：http自1.1开始都是默认保持Http长连接，rpc虽然也是基于长连接，但是rpc还维护了一个连接池
传输内容：http设计之初是用来网页显示文本，多以字符串为主，rpc可以通过protobuf将数据和自定义结构体
序列化为二进制数据


tcp除了三次握手外，还有哪些机制实现可靠传输：
0.连接建立：三次握手建立连接
1.序号与确认
2.重传机制
3.滑动窗口
4.流量控制
5.拥塞控制


http和tcp的区别：
1.http是应用层协议，而tcp是传输层协议
2.tcp是面向连接的，而http1.0是无连接的，发送数据时需要建立tcp连接
3.tcp是基于字节流的，而http是有固定的数据格式的
4.tcp是可靠的传输，而http本身不保证数据的可靠传输，通过tcp进行保证。


如果一个进程奔溃了怎么排查：
使用ps -aux | grep 进程名称 查看进程的内存占用百分比和实际使用的内存大小。
如果进程占用的内存过大，可能会导致内存不足而崩溃。
使用top查看进程内存使用情况

如果进程cpu占用率过高该怎么排查:
可以通过top命令,然后再按下P键可以按照cpu占有率进行排序

执行Update语句如果没有走索引的话会给每个记录都加上next-key-lock，这样就会锁住全表
避免锁住全表的方法是：使用where条件中必须要有索引列，如果where中有索引列但还是走了全表扫描
则可以通过force index来指定使用哪个索引进行查询


怎么降低锁竞争：
1.减小锁的粒度：将大对象的锁拆分为多个小对象锁，使得不同线程可以访问不同部分。
2.优化锁持有的时间，减少锁持有期间代码的执行时间
3.在读多写少的情况下可以采用读写分离锁。

为什么要合并页表：
因为硬件mmu只能解析一个页表，当处于内核态时，mmu只能解析内核页表，但如果此时想要访问用户页表，比如
想要访问用户传进来的一个指针，此时只能通过软件的方法解析用户页表，性能是比不上mmu的，所有合并页表可以使得
mmu此时还可以访问用户页表

合并页表不会产生冲突吗：
内核态页表采用直接物理地址映射，且在0-0x8000000的地址属于硬件地址，所以将用户页表映射到这部分地址不会
产生冲突。


为什么能让所有虚拟内存之和超过物理内存：
因为操作系统提供的缺页中断机制，以及写时复制，懒分配和磁盘交换等机制，使得很大虚拟地址实际上并没有分配
实际的物理地址，只有当真正使用到这些虚拟地址的时候才去分配，所以看上去虚拟内存远超了物理内存

自旋锁底层实现原理：
自旋锁是通过test-and-set原子指令实现，当两个进程都进入到判断锁的locked字段是否为0时，通过原子
指令可以使得其中一个进程将locked置为1，即其中一个进程获得锁，另外一个线程等待锁。

sleep-lock:通过自旋锁加循环加sleep函数组成


buffer cache实验是怎么降低锁争用的：
因为缓存块是通过一个链表连接的，所以多进程去访问链表是需要进行加锁，加锁之后会形成串行访问，访问效率不高
所以可以将缓存块分为多个链表连接，每个链表一个锁，从而可以使得多个线程去获得各自的锁，降低了锁的争用。

睡眠锁和自旋锁适用的场景：
因为自旋锁会一直自旋等待，直到获得锁位置，这个过程会一直占用cpu资源，所以自旋锁在等待时间非常短的情况下
比较高效。而睡眠锁在等待锁的时候可以将cpu资源转移给其他进程使用，使用睡眠锁适用于等待时间比较长的情况。

怎么处理死锁问题：
检测死锁：
1.将锁看做是资源节点，线程获取锁的顺序为有向边，检测资源图中是否会产生环
2.检查多线程是不是以不同的顺序获取锁，不同线程以不同的顺序获取锁是导致死锁的最常见的问题
3.使用try_lock 超时机制：申请锁时设置超时时间，若超时则释放已持有锁并重试，打破 “持有并等待”
try_lock的原理是尝试获取所有锁，如果成功获取所有的锁，则返回0，如果失败，则返回获取失败的锁的索引，并且
释放已获得的锁

预防死锁：
1.避免多重锁定，避免一个线程获取多个不同的锁，如果需要获取不同的锁的时候应该保证所有线程以相同的顺序
获得锁。
2.超时机制：在等待获取锁时起一个定时器，当等待超过定时时间时自动放弃对于锁的获取。
3.尽量保证线程以相同的顺序请求资源。

段错误除了数组越界和野指针外还会由什么情况造成：
还会由栈溢出造成：
1.程序员使用栈内存超过系统分配的栈内存大小，比如进入死循环或者递归层数过度，或者变量过大。
2.重复释放内存
3.程序员手动释放非动态内存，比如由malloc申请的内存


自动类型推导(必须从表达式进行推导):auto和decltype
auto只能用于初始化的场景(向编译器索取类型)，即右边必须是个表达式才能进行自动类型推导,但是注意在
类的成员变量初始化的时候不能用auto进行自动类型推导。
auto总是推导出的是值类型，但是可以使用const,volatile,&,*这样的类型修饰符修饰，得到其他的类型。
auto还可以解决硬编码的问题，比如你之前表达式用的是map,现在换成unordered_map也是没有问题的。
由于自动类型推导其实是必须从表达式进行类型推导的，decltype自给自足的提供了括号，形如decltype(x),
所以可以直接这样使用，并且decltype是直接推导出变量的原类型。

mmap:
这是一种将文件或者其他对象映射到虚拟地址空间的机制，使得进程可以像访问内存一样去访问文件数据，可以避免
使用read/write这样的系统调用。
原理：将进程虚拟地址和文件的磁盘地址形成一种映射关系，首先分配一段连续的虚拟地址区间(VMA)，VMA记录了
文件描述符，偏移量等内容，并且在页面中建立VMA和磁盘地址的映射关系，但是此时并不实际分配物理内存，而是
当实际访问到VMA区域的虚拟地址的时候，由于虚拟地址没有对应的物理内存，会触发缺页中断，然后操作系统
分配一个物理页面，并且根据VMA中记录的信息通过文件系统将磁盘数据加载到刚刚分配的物理页面，然后将虚拟
地址和物理内存相关联。
数据同步：修改如何写回文件？
共享映射（MAP_SHARED）：进程对映射区的修改会自动同步到文件（内核会在合适的时机，
如物理内存页被置换前、调用 msync 或进程退出时，将物理内存中的数据写回磁盘文件）。
私有映射（MAP_PRIVATE）：进程对映射区的修改仅在当前进程可见（采用 “写时复制” 机制：
首次修改时，内核会复制一份物理内存页，修改新页，原页保持与文件一致，因此不会影响原文件）。

mmap和传统IO的区别：
read/write:需要两次数据拷贝
磁盘-》内核缓冲区-》用户缓冲区
mmap:一次数据拷贝
磁盘-》物理内存页-》直接映射到用户虚拟地址，不需要数据拷贝

共享内存和mmap（内存映射）:
1.共享内存是直接分配一块物理内存供进程共享依赖的是操作系统，mmap是将文件和设备映射到进程的地址空间
依赖的是文件系统
2.共享内存的数据只存在于内存中，数据可能会发生丢失。mmap如果映射的是磁盘文件，数据的修改可以同步到
磁盘上


内存泄漏检测工具:valgrind
运行valgrind(默认使用memcheck工具)
valgrind --leak-check=full ./myprogram
--leak-check=full：开启完整的内存泄漏检测（推荐）。
输出结果中会包含错误类型、发生位置（文件名和行号）、详细描述等。


背包问题：
0-1背包：如果是二维数组遍历顺序可以随意，如果是一维数组，需要先遍历物品，再倒序遍历背包。
完全背包：如果是二维数组时求的结果不涉及组合数和排列数的话遍历顺序是可以随意的。
如果求组合数就要先遍历物品在遍历背包，如果求排列数就要先遍历背包再遍历物品


-----------------------------------------------------------------------------------
简历项目总结：
基于 C++11标准重构高性能网络库Muduo库网络通信模块:

这个项目的亮点是什么：
1.代码更简洁高效
利用auto关键字简化类型声明，尤其是在处理复杂迭代器和模板类型时
基于范围的 for 循环 (for (auto& elem : container)) 替代传统 for 循环，减少代码量
nullptr替代NULL，避免整数和指针类型混淆
2.内存管理更安全
智能指针 (std::shared_ptr/std::unique_ptr) 替代原始指针，减少内存泄漏风险
移动语义 (std::move) 减少不必要的对象拷贝，提升性能
std::make_shared优化内存分配，减少堆内存碎片
3.并发编程更完善
直接使用 C++11 标准库的线程库 (std::thread) 替代平台特定线程 API
利用std::mutex/std::lock_guard/std::unique_lock简化线程同步
条件变量 (std::condition_variable) 提供更标准的线程通信方式
std::atomic实现无锁编程，提升并发性能
4.功能扩展更便捷
lambda 表达式简化回调函数编写，尤其适合事件驱动型网络库
右值引用支持实现更高效的对象传递
std::function和std::bind提供更灵活的函数对象封装

thread_local:通过thread_local修饰的变量在每个线程中都有一份独立的实例，各个线程之间互不干扰，该变量
的生命周期和线程一致，解决了多线程下对于共享变量竞争的问题

通过函数绑定器std::bind来实现了大量的回调函数==>可能考察函数绑定器部分的知识.......

muduo库对于IO的处理以及对于业务逻辑处理的分离：
muduo 常用 one loop per thread + thread pool 模型：
I/O 线程（运行 EventLoop）专注于处理 I/O 事件，不阻塞。
业务逻辑可交给线程池异步处理，处理完成后通过 EventLoop 回调更新结果（如发送响应）。
这种模型下，业务逻辑的 “计算密集型” 操作通常是异步的（在非 I/O 线程执行），而 “轻量操作” 可同步执行。


通过轮询分发了找到一个subLoop时，是直接将这个IO事件向这个subLoop上进行注册吗，不需要关心该subLoop是否在处理事件吗？
这里的主要原理是：当轮询找到了一个subLoop之后，会调用subLoop.runInLoop函数，该函数会首先进行判断当前线程是否处于
subLoop的线程，如果是的话就直接执行将新用户的文件描述符往subLoop上进行注册。否则将执行queueInLoop,将绑定给subLoop
的回调放入到一个任务队列中，然后再去唤醒loop，而且因为分发新用户的连接时，肯定不是属于runinloop的逻辑
所以肯定走的是queueinloop。之所以不需要考虑此时的loop是否是在执行任务是因为在loop循环从epoll_wait
中醒过来进行事件处理，处理完之后，还会将mainloop分发给subloop并且存在任务队列中的任务执行完(这个任务其实就是注册新用户
文件描述符到subloop中)，所以后续如果该文件描述符有任务到来则可以直接从epoll_wait中醒过来，执行相应的事件

线程池关闭时，怎么知道每个线程是不是还在执行任务，如果在执行任务，应该怎么样去做，是等待吗？
首先需要明确的是，当要关闭线程池时，需要保证各个线程将自己的任务全部执行完，不能线程任务还没有执行完就关闭。所以采取
的是这样的方式：首先eventLoopThreadPool循环遍历subLoop，每个subLoop调用quit方法，quit中会判断当前线程是否是subloop线程
很明显，当前线程是处于主线程，不处于subLoop线程，所以会唤醒每一个subloop线程，唤醒每一个subloop线程的目的是让subLoop
去完成之前主线程给它的任务队列里面添加的任务，保证在关闭线程池的时候所有任务都完成。


为什么向wakeupfd中写入一个数据就能唤醒一个subloop？
因为子循环subloop通常阻塞在epoll_wait状态下，当将wakeupfd添加到epoll上后，如果向wakeupfd
写入一个数据，子循环会从epoll_wait获取到这个可读fd,进而执行预先设置好的可读事件的回调函数。

项目中有使用shared_from_this,和enable_shared_from_this，可以引导展开.......

使用eventfd创建wakeupfd的好处？
eventfd是内核维护的64位计数器，其创建的开销比管道小很多。并且它天然支持IO多路复用，可以直接注册到
epoll中，多个线程向eventfd写入数据时不需要加锁，其内部会保证原子性操作。

在创建线程时使用了信号量，子线程需要获取到其进程的tid，所以主进程必须等待子进程创建完成之后才可以
进行运行，所以在主进程处sem_wait(&sem)，当子进程创建完成，sem_post(&sem)之后，主进程才继续进行

one loop per thread的思想最主要出现在：创建一个新线程，在执行线程函数时，在线程函数中会创建
处一个eventloop，一个线程对应一个eventloop，该eventloop开启事件循环

Acceptor是运行在mainloop中的，并且Acceptor专门用来监听并接收一个新用户的连接，并且通过轮询找到一个
subloop，唤醒subloop并分发这个连接.

自定义Buffer类，通过定义iovec结构体和readv函数来实现一次性将tcp缓冲区中的数据全部读入Buffer缓冲区。
iovec 结构体数组，用于 readv 系统调用实现分散读（scatter-gather I/O）。
其核心作用是：让一次 read 操作可以将数据写入到多个不连续的内存缓冲区中，
避免因单个缓冲区空间不足而需要多次读取的问题。
通过readv系统调用会先将数据读入到buffer的缓冲区中，如果Buffer缓冲区的大小不够，接着再读到后续在栈上
开辟的数组中，然后再通过append函数将数组追加到buffer缓冲区中，buffer缓冲区可能会扩容
需要注意的是，为了满足readv函数调用的使用，在栈上开辟了extrabuf，在栈上开辟而不在堆上开辟的主要原因是：
在栈上分配只需要移动栈指针，而在堆上分配的话还需要区需找空闲的内存块。并且栈上分配的空间由操作系统
自动释放，而堆上的需要手动释放。


struct iovec {
    void  *iov_base;  // 指向缓冲区的起始地址
    size_t iov_len;   // 缓冲区的长度（字节数）
};


----------------------------------------------------------------------------------
基于 C++实现的高性能分布式网络通信框架:

业务模块：
ORM框架：框架是一种将面向对象编程（OOP）中的对象模型与关系型数据库中的表结构进行映射的技术框架
核心思想：将数据库表映射为程序中的类，表的字段映射为类的属性，表中的每一行数据映射为类的一个实例对象。
将对对象的操作（如创建、查询、更新、删除）自动转换为对应的 SQL 语句执行，开发者无需手动编写 SQL。

部署多台服务器，并基于nginx负载均衡对客户端连接进行分发，nginx根据负载均衡算法将具体业务分发到
chatserver上,并且需要nginx和chatserver保持心跳，需要检测chatserver是否故障,采用负载均衡器也能更加
方便的添加服务器设备

当登录在不同服务器上的用户需要进行通信时，需要引入redis中间件，而不让服务器之间互相建立连接，服务器
之间互相建立连接的话会非常复杂，每个服务器都需要与和它相连的服务器之间保持心跳，服务器之间的耦合度
太高。此处是采用了redis的发布订阅功能，用户可以向redis中订阅指定channel(id)的消息，当该指定channel向
redis中发布信息，redis会将信息推送给订阅过的用户，这个部分其实是采用了设计模式中的观察者模式，
可以根据这里展开到观察者模式的内容......

redis作为集群服务器通信基于发布-订阅消息队列时会出现的问题：
1.当发布者与redis之间出现网络延迟等问题，消息可能无法及时到达，导致消息丢失。
2.订阅者处理消息速度过慢，导致消息积压在队列中，而redis内存有限,可能会导致新消息覆盖旧消息
3.在redis集群中，消息可能会被发到不同的节点进行处理，由于各节点处理速度不同，导致消息到达订阅者的顺序
与发布的顺序不一致。


分布式模块:
服务发布方：
以callee中的一个userservice服务为例进行讲解：
1.定义出要往rpc节点上发布的方法，该方法继承自rpc发布端，在定义proto文件的时候就会生成对应方法的rpc
2.使用框架，对框架进行初始化，生成一个rpcprovider对象，通过该对象的notifyservice方法将方法发布到
rpc节点上去
3.调用start方法开启rpc服务节点

rpcprovider模块讲解：
主要包括了两个方法：notifyservice方法和start方法，分别是将发布的rpc方法存储下来以及开启rpc节点。同时
rpcprovider模块也包含了muduo库的网络通信模块，可以用于调用方和发布方直接的网络通信。
start方法中主要是进行muduo库中网络通信相关的内容，设置线程池的线程数量，注册连接回调和读写事件回调等
其中需要注意的是读写事件的回调：在rpc发布方和rpc调用方之间需要协商好通信用的protobuf通信用的数据类型，
其中包括service_name,method_name和arg_size这三部分。
之后是序列化拿到调用方的请求参数，并且提前定义出完成本地方法后执行的回调函数，该回调函数实际上做的事情
就是序列化rpc的响应以及进行网络发送。之后使用service->callmethod的方法，来实际调用rpc发布的服务完成本地服务

服务调用方：
以caller中的userservice服务为例进行讲解：
首先初始化框架，然后创建rpc_stub对象，注意该stub对象的创建需要传入一个rpcChannel才能完成，之后设置
请求的参数和接收请求的响应，然后通过stub来调用具体的方法，通过stub来调用的方法最后都会走到rpcChannel的callmethod方法
来完成统一的方法调用和网络请求发送以及数据序列化和反序列化，完成方法后响应内容就被填充完成了，
所以效果上就类似于在本地调用了方法一样


protobuf和json相比好处是什么:
1.protobuf采用二进制存储，json采用文本存储，所以protobuf序列化和反序列化速度更快,并且protobuf存储数据
所占空间比json小，比如一个10000的数字，json要存成'10000'的形式，占的内存就不止int，而protobuf采用二进制
存储，只要是在int类型范围下的数据都只需要4个字节进行存储
2.protobuf不需要存储额外的信息，json是通过键值对进行存储的
3.protobuf可以通过.proto文件来定义数据结构，比如message类型数据结构和service类型的数据结构
其中service会产生serviceRpc和service_stub这两个类，前面一个是用来给rpc发布端进行使用的，后面
那个是给客户端进行调用的

Mprpc框架下的主要内容:
1.MprpcApplication框架的初始化
2.Rpcprovider:
muduo库完成网络的发送和接收，protobuf完成请求和响应的序列化和反序列化，NotifyService完成将
服务发布到Rpc节点上去，并且记录服务的方法和名称

Rpc框架的发布方即Rpcprovider的使用者主要做的事情：
1.获取Rpc调用方通过Muduo网络库发送过来的request请求，从请求中获取参数
2.根据参数执行本地的方法
3.将执行结果填充到response中
4.将response通过提前注册好的done回调(通过网络库发送回Rpc调用方)

Rpc调用方主要做的事情：
1.初始化框架，因为要通过框架进行rpc服务的调用
2.通过RpcChannel来定义一个Rpc_Stub
3.封装Rpc服务调用的请求
4.根据方法名通过stub发起rpc调用：实际上是通过RpcChannel中的callmethod方法来进行参数的序列化和反序列化
以及网络发送和接收



zookeeper学习：https://www.cnblogs.com/xinyonghu/p/11031729.html
zookeeper消息注册中心要求所有的服务首先在注册中心进行注册，这样注册中心保存了服务的IP地址和端口号
同时客户端每次再访问服务之前都需要先向注册中心进行询问，拿到服务的ip地址和端口号，然后才能访问
具体的服务，并且客户端还需要对某个Znode建立一个watcher监听事件，当znode发生变化时会马上通知客户端。
而且zookeeper还需要和每个服务实例建立session会话，要求服务实例定期发送心跳消息，收不到心跳消息
就任务服务节点挂了，删除服务实例


----------------------------------------------------------------------

*/




#endif